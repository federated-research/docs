# Run an Analysis

## Requirements

### Infrastructure requirements
* Fully deployed Five Safes TES stack
* At least one TRE
* [OMOP CDM database](/standards#observational-medical-outcomes-partnership-omop) connected to each TRE (the default demo expects an OMOP database)

### Information requirements
* Project name
* TES endpoint
* Minio endpoint
* Database endpoint and credentials for each TRE
* TRE access
* Submission layer endpoint and credentials

It is assumed that the full five safes TES stack is already fully deployed, and you have all the required information to hand. You will also need to have the TREs set up and know how to get an access token, so it's strongly recommended that you go through the environment verification first.

## Setup
1. Clone the repository (https://github.com/Health-Informatics-UoN/Five-Safes-TES-Analytics)
2. Install dependencies (using poetry is recommended, ```poetry install```), or use pip
```pip install -r requirements.txt```
3. Edit the `env.example` file to update the environment variables.
4. Rename the `env.example` to `.env`
5. Log in to the submission layer GUI.
6. Retrieve a token - This has a limited lifetime! 
   Click 'API Access Token' on the top, then renew and copy the token to clipboard.
7. Paste the token into the `.env` file and save the file.

## Run an analysis
This runs the basic default demo, which will calculate means of measurement values with a particular concept id (`3037532`).

3. Run `analysis_engine.py`. Using poetry, the command is:
 ```poetry run python analysis_engine.py```
 4. Review the submission details. Terminal will give updates on the submission status, the submission GUI will give more details under the submissions tab.
 5. Wait.
 6. When the processing is complete, the status in the submission layer will change to waiting for egress. This means that the analysis has been processed and needs to be approved before the results can leave the TREs.
 7. Acting as the TREs, log into the egress control(s) and approve (or deny) the egress. The default behaviour is to complete the analysis with the results given, even if one or more TREs don't provide results. Once they have been approved, the status in both the submission layer GUI and the terminal will be updated the next time it polls.
 8. The partial results from each TRE will be fetched automatically.
 9. The partial results will be aggregated and return the final result to the terminal.



## Next steps
The next step is to run a different analysis on a different subset of data.

The general way to use the tool is to use it in a python environment rather than running from the terminal. 

The data selection is done with an SQL query. This is simply to select a subset of data to run the analysis on. Change the user query to select the data you want to run the analysis on.

Supported analysis types are currently "mean", "variance", "PMCC", "chi_squared_scipy" and "chi_squared_manual".

Once the analysis is completed, the aggregated data is stored in the engine, and the analysis, or related analyses, can be repeated without further queries to the TREs.

```
import analysis_engine

engine = analysis_engine.AnalysisEngine()

# Example
user_query = """SELECT value_as_number FROM public.measurement
WHERE measurement_concept_id = 3037532
AND value_as_number IS NOT NULL"""

print("Running mean analysis...")

mean_result = engine.run_analysis(
analysis_type="mean",
task_name="DEMO: mean analysis test",
user_query=user_query,
tres=["Nottingham", "Nottingham 2"]
)

print(f"Mean analysis result: {mean_result['result']}")
# Show what aggregated data we have stored
print(f"Stored aggregated data: {engine.aggregated_data}")
```
